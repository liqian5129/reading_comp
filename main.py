#!/usr/bin/env python3
"""
AI è¯»ä¹¦æ­å­ - ä¸»ç¨‹åº
"""
import asyncio
import logging
import signal
import sys
import time
from pathlib import Path
from typing import Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger("main")

# å¯¼å…¥æ¨¡å—
from config import config, Config
from session.storage import Storage
from session.manager import SessionManager
from agent.ai_client import AIClient
from agent.memory import Memory
from agent.tools import ToolRegistry, ToolExecutor
from agent.timer_manager import ReadingTimerManager
from scanner.vision_analyzer import VisionAnalyzer
from scanner.auto_scanner import AutoScanner
from voice.asr import AliyunStreamASR, create_asr
from voice.recorder import VoiceRecorder
from feishu.bot import FeishuBot
from feishu.push import SummaryPusher


class ReadingCompanion:
    """
    AI è¯»ä¹¦æ­å­ä¸»ç±»
    """

    def __init__(self):
        # è°ƒè¯•æ¨¡å¼ä¸‹è·³è¿‡ API key æ£€æŸ¥
        if config.DEBUG_MODE:
            logger.info("âš ï¸  è°ƒè¯•æ¨¡å¼å·²å¯ç”¨ï¼Œè·³è¿‡ API é…ç½®éªŒè¯")
        else:
            missing = config.validate()
            if missing:
                logger.error(f"ç¼ºå°‘é…ç½®é¡¹: {', '.join(missing)}")
                logger.error("è¯·è¿è¡Œ: python setup.py ç”Ÿæˆé…ç½®æ–‡ä»¶")
                sys.exit(1)

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        config.ensure_dirs()
        
        # ä¿å­˜äº‹ä»¶å¾ªç¯å¼•ç”¨ï¼ˆç”¨äºè·¨çº¿ç¨‹è°ƒåº¦ï¼‰
        self.loop: Optional[asyncio.AbstractEventLoop] = None
        
        # åˆå§‹åŒ–å„æ¨¡å—
        self.storage: Optional[Storage] = None
        self.session_manager: Optional[SessionManager] = None
        self.llm: Optional[AIClient] = None
        self.memory: Optional[Memory] = None
        self.tool_registry: Optional[ToolRegistry] = None
        self.tool_executor: Optional[ToolExecutor] = None
        self.scanner: Optional[AutoScanner] = None
        self.vision_analyzer: Optional[VisionAnalyzer] = None
        self.timer_manager: Optional[ReadingTimerManager] = None
        self.asr: Optional[AliyunStreamASR] = None
        self.recorder: Optional[VoiceRecorder] = None
        self.tts_player = None
        self.feishu_bot: Optional[FeishuBot] = None
        self.summary_pusher: Optional[SummaryPusher] = None
        
        # çŠ¶æ€
        self._running = False
        self._last_valid_ocr_ts: float = 0.0  # ä¸Šæ¬¡æœ‰æ•ˆ OCR çš„æ—¶é—´æˆ³
        
    async def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ¨¡å—"""
        logger.info("æ­£åœ¨åˆå§‹åŒ–...")

        # ä¿å­˜äº‹ä»¶å¾ªç¯å¼•ç”¨
        self.loop = asyncio.get_running_loop()

        # 1. æ•°æ®åº“
        self.storage = Storage(config.SESSIONS_DB, notes_dir=config.NOTES_DIR)
        await self.storage.initialize()

        # 2. ä¼šè¯ç®¡ç†
        self.session_manager = SessionManager(self.storage)

        if config.DEBUG_MODE:
            # --- è°ƒè¯•æ¨¡å¼ï¼šåªå¯åŠ¨æ‘„åƒå¤´+OCRï¼Œè·³è¿‡ AI/ASR/TTS/é£ä¹¦ ---
            logger.info("ğŸ”§ è°ƒè¯•æ¨¡å¼ï¼šè·³è¿‡ AI / ASR / TTS / é£ä¹¦åˆå§‹åŒ–")

            self.scanner = AutoScanner(self.session_manager)
            self.scanner.on_snapshot = self._on_snapshot
            if config.SCANNER_ENABLED:
                await self.scanner.start()
            else:
                logger.info("ğŸ“· æ‘„åƒå¤´/OCR æ‰«æå·²ç¦ç”¨ï¼ˆcamera.scanner_enabled=falseï¼‰")

            logger.info("åˆå§‹åŒ–å®Œæˆï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰")
            return

        # --- æ­£å¸¸æ¨¡å¼ ---

        # 3. AI å®¢æˆ·ç«¯ï¼ˆæ”¯æŒ Kimi æˆ–è±†åŒ…ï¼‰
        if config.AI_PROVIDER == "kimi":
            self.llm = AIClient(
                provider="kimi",
                api_key=config.KIMI_API_KEY,
                model=config.KIMI_MODEL,
                base_url=config.KIMI_BASE_URL,
                enable_thinking=config.KIMI_ENABLE_THINKING
            )
        else:  # doubao
            self.llm = AIClient(
                provider="doubao",
                api_key=config.DOUBAO_API_KEY,
                model=config.DOUBAO_MODEL,
                base_url=config.DOUBAO_BASE_URL
            )

        self.memory = Memory(config.PERSONA_FILE, long_term_file=config.LONG_TERM_MEMORY_FILE)
        self.tool_registry = ToolRegistry()
        self.timer_manager = ReadingTimerManager()

        # 4. æ‰«æå™¨
        self.scanner = AutoScanner(self.session_manager)
        self.scanner.on_snapshot = self._on_snapshot
        if config.SCANNER_ENABLED:
            await self.scanner.start()
        else:
            logger.info("ğŸ“· æ‘„åƒå¤´/OCR æ‰«æå·²ç¦ç”¨ï¼ˆcamera.scanner_enabled=falseï¼‰")

        # 4b. è§†è§‰åˆ†æå™¨ï¼ˆéœ€è¦æ”¯æŒå›¾ç‰‡çš„æ¨¡å‹ï¼Œé»˜è®¤å…³é—­ï¼‰
        if config.VISION_ANALYZER_ENABLED:
            if config.VISION_MODEL == config.CURRENT_MODEL:
                vision_llm = self.llm  # åŒä¸€æ¨¡å‹ï¼Œå¤ç”¨å®¢æˆ·ç«¯
            else:
                vision_llm = AIClient(
                    provider="kimi",
                    api_key=config.VISION_API_KEY,
                    model=config.VISION_MODEL,
                    base_url=config.VISION_BASE_URL,
                )
                logger.info(f"ğŸ”­ è§†è§‰åˆ†æå™¨ä½¿ç”¨ç‹¬ç«‹æ¨¡å‹: {config.VISION_MODEL}")
            self.vision_analyzer = VisionAnalyzer(
                ai_client=vision_llm,
                on_book_detected=self._on_book_detected,
            )
            self.scanner.set_vision_analyzer(self.vision_analyzer)
            logger.info("ğŸ”­ è§†è§‰åˆ†æå™¨å·²å¯ç”¨")
        else:
            logger.info("ğŸ”­ è§†è§‰åˆ†æå™¨å·²ç¦ç”¨ï¼ˆvision.enabled=falseï¼Œkimi-k2.5 ä¸æ”¯æŒå›¾ç‰‡ï¼‰")

        # 5. å·¥å…·æ‰§è¡Œå™¨ï¼ˆä¾èµ– scanner å’Œ session_managerï¼‰
        self.tool_executor = ToolExecutor(
            session_manager=self.session_manager,
            scanner=self.scanner,
            memory=self.memory,
            llm=self.llm,
            timer_manager=self.timer_manager,
        )

        # 6. è¯­éŸ³
        self.asr = create_asr(
            app_key=config.ALIYUN_NLS_APP_KEY,
            token=config.ALIYUN_NLS_TOKEN,
            access_key_id=config.ALIYUN_NLS_ACCESS_KEY_ID,
            access_key_secret=config.ALIYUN_NLS_ACCESS_KEY_SECRET,
        )
        self.recorder = VoiceRecorder(
            self.asr,
            loop=self.loop,
            sample_rate=16000,
            channels=1,
            min_duration=0.3
        )
        self.recorder.on_text = self._on_voice_text

        # 7. TTSï¼ˆæ”¯æŒé˜¿é‡Œäº‘æˆ– ElevenLabsï¼‰
        from tts import create_tts_player
        self.tts_player = create_tts_player(config)
        await self.tts_player.start()
        # æŠŠ TTS æ³¨å…¥å®šæ—¶å™¨ï¼ˆæ— è®ºé£ä¹¦æ˜¯å¦å¯ç”¨éƒ½èƒ½æ’­æŠ¥ï¼‰
        self.timer_manager.set_tts_player(self.tts_player)

        # 8. é£ä¹¦ Botï¼ˆå¯é€‰ï¼‰
        if config.FEISHU_ENABLED and config.FEISHU_APP_ID and config.FEISHU_APP_SECRET:
            self.feishu_bot = FeishuBot(
                app_id=config.FEISHU_APP_ID,
                app_secret=config.FEISHU_APP_SECRET,
                encrypt_key=config.FEISHU_ENCRYPT_KEY,
                verification_token=config.FEISHU_VERIFICATION_TOKEN,
                message_handler=self._handle_feishu_message,
                loop=self.loop
            )
            self.summary_pusher = SummaryPusher(self.feishu_bot)
            self.feishu_bot.start()
            logger.info("é£ä¹¦ Bot å·²å¯åŠ¨")

            # å°†é£ä¹¦ pusher æ³¨å…¥ ToolExecutor å’Œ TimerManager
            feishu_chat_id = getattr(config, "FEISHU_DEFAULT_CHAT_ID", "")
            self.tool_executor.feishu_pusher = self.summary_pusher
            self.tool_executor.feishu_chat_id = feishu_chat_id
            self.timer_manager.set_tts_player(self.tts_player)
            self.timer_manager.set_feishu(self.summary_pusher, feishu_chat_id)

        logger.info("åˆå§‹åŒ–å®Œæˆ")
    
    async def shutdown(self):
        """å…³é—­æ‰€æœ‰æ¨¡å—"""
        logger.info("æ­£åœ¨å…³é—­...")

        self._running = False

        if self.timer_manager:
            self.timer_manager.cancel_all()
        if self.vision_analyzer:
            await self.vision_analyzer.cancel()
        if self.recorder:
            self.recorder.stop()
        if self.scanner and self.scanner.is_running():
            await self.scanner.stop()
        if self.tts_player:
            await self.tts_player.stop()
        if self.feishu_bot:
            self.feishu_bot.stop()
        if self.storage:
            await self.storage.close()

        logger.info("å·²å…³é—­")
    
    async def run(self):
        """ä¸»è¿è¡Œå¾ªç¯"""
        await self.initialize()

        self._running = True

        if config.DEBUG_MODE:
            logger.info("=" * 60)
            logger.info("ğŸ”§ AI è¯»ä¹¦æ­å­å·²å¯åŠ¨ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰")
            logger.info("   ASR / AI / TTS / é£ä¹¦ å‡å·²ç¦ç”¨")
            if self.scanner and self.scanner.is_running():
                logger.info(f"   æ‘„åƒå¤´+OCR å·²å¯åŠ¨ï¼Œé—´éš” {config.AUTO_SCAN_INTERVAL}s")
            else:
                logger.info("   æ‘„åƒå¤´/OCR æœªå¯åŠ¨ï¼ˆscanner_enabled=falseï¼‰")
            logger.info("=" * 60)
        else:
            # å¯åŠ¨å½•éŸ³ç›‘å¬
            self.recorder.start()

            logger.info("=" * 60)
            logger.info("ğŸ‰ AI è¯»ä¹¦æ­å­å·²å¯åŠ¨ï¼")
            logger.info(f"ğŸ¤– AI æä¾›å•†: {config.AI_PROVIDER}")
            logger.info(f"ğŸ¤– AI æ¨¡å‹: {config.CURRENT_MODEL}")
            logger.info(f"ğŸ”Š TTS æä¾›å•†: {config.TTS_PROVIDER}")
            logger.info("æŒ‰ä½ ã€å³ Alt é”®ã€‘è¯´è¯ä¸ AI äº¤æµ")
            logger.info("=" * 60)
        
        # ä¿æŒè¿è¡Œ
        try:
            while self._running:
                await asyncio.sleep(1)
        except asyncio.CancelledError:
            pass
        
        await self.shutdown()
    
    async def _on_voice_text(self, text: str):
        """å¤„ç†è¯­éŸ³è¯†åˆ«ç»“æœï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰"""
        logger.info(f"ğŸ‘¤ ç”¨æˆ·: {text}")
        await self._process_user_message(text)
    
    async def _process_user_message(self, text: str, channel: str = "voice"):
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯ - å¸¦å®Œæ•´é“¾è·¯è®¡æ—¶
        """
        logger.info("=" * 60)
        logger.info("ğŸš€ å¼€å§‹å¤„ç†ç”¨æˆ·æ¶ˆæ¯")
        logger.info(f"   è¾“å…¥: {text[:50]}...")
        logger.info("=" * 60)
        
        # æ•´ä½“é“¾è·¯è®¡æ—¶
        start_time = time.time()
        
        try:
            # 1. è°ƒç”¨ LLM
            logger.info("â³ 1. å‡†å¤‡è°ƒç”¨ LLM...")
            system_prompt = self.memory.build_system_prompt()
            history = self.memory.get_history()
            tools = self.tool_registry.get_tools()
            page_ctx_len = len(self.memory.current_page_ocr)
            logger.info(f"   å†å²æ¶ˆæ¯æ•°: {len(history)}, å·¥å…·æ•°: {len(tools)}, "
                        f"ä¹¦é¡µä¸Šä¸‹æ–‡: {page_ctx_len}å­—"
                        + (" âœ“" if page_ctx_len else " (æ— )"))
            
            response = await self.llm.chat(
                user_message=text,
                system_prompt=system_prompt,
                history=history,
                tools=tools
            )
            
            llm_done_time = time.time()
            
            # 2. å¤„ç†å·¥å…·è°ƒç”¨
            if response.tool_calls:
                tool_results = []
                for tool_call in response.tool_calls:
                    result = await self.tool_executor.execute(
                        tool_call["name"],
                        tool_call["input"]
                    )
                    tool_results.append({
                        "tool_use_id": tool_call["id"],
                        "content": str(result)
                    })

                final_response = await self.llm.chat_with_tool_result(
                    user_message=text,
                    tool_results=tool_results,
                    system_prompt=system_prompt,
                    history=history,
                    assistant_message=response.raw_assistant_message,
                )
                
                reply_text = final_response.text
            else:
                reply_text = response.text
            
            tool_done_time = time.time()
            
            # æ‰“å° AI å›å¤å†…å®¹
            logger.info("=" * 60)
            logger.info("ğŸ¤– AI å›å¤å†…å®¹:")
            logger.info("-" * 60)
            # å¤šè¡Œæ˜¾ç¤ºï¼Œæ¯è¡Œæœ€å¤š 58 å­—ç¬¦
            for line in reply_text.split('\n'):
                while line:
                    chunk = line[:58]
                    line = line[58:]
                    logger.info(f"  {chunk}")
            logger.info("-" * 60)
            logger.info(f"ğŸ“Š å›å¤é•¿åº¦: {len(reply_text)} å­—ç¬¦, {len(reply_text.split())} è¯")
            logger.info("=" * 60)
            
            # 3. è®°å½•å¯¹è¯å†å²
            self.memory.add_message("user", text)
            self.memory.add_message("assistant", reply_text)
            
            # 4. è¯­éŸ³æ’­æŠ¥ï¼ˆå¸¦ TTS æ—¶é—´è®¡ç®—ï¼‰
            if channel == "voice" and reply_text:
                logger.info("ğŸ”Š å¼€å§‹ TTS è½¬æ¢...")
                await self.tts_player.speak(reply_text, interrupt=True)
                # ç­‰å¾…åˆæˆå®Œæˆï¼ˆä¸ç­‰æ’­æ”¾ï¼‰ï¼Œè·å–çœŸå®åˆæˆè€—æ—¶
                if hasattr(self.tts_player, 'wait_synthesized'):
                    tts_time = await self.tts_player.wait_synthesized(timeout=30.0)
                else:
                    tts_time = 0
                logger.info(f"âœ… TTS åˆæˆå®Œæˆï¼Œè€—æ—¶: {tts_time:.0f} ms")
            else:
                tts_time = 0
            
            end_time = time.time()
            
            # æ‰“å°å®Œæ•´é“¾è·¯åˆ†æ
            total_time = (end_time - start_time) * 1000
            llm_time = (llm_done_time - start_time) * 1000
            tool_time = (tool_done_time - llm_done_time) * 1000 if response.tool_calls else 0
            
            logger.info("â•”" + "=" * 58 + "â•—")
            logger.info("â•‘" + " ğŸ“Š å®Œæ•´é“¾è·¯è€—æ—¶åˆ†æ ".center(54) + "â•‘")
            logger.info("â• " + "=" * 58 + "â•£")
            logger.info(f"â•‘  LLM æ¨ç†:     {llm_time:>6.0f} ms                          â•‘")
            if response.tool_calls:
                logger.info(f"â•‘  å·¥å…·æ‰§è¡Œ:     {tool_time:>6.0f} ms                          â•‘")
            if tts_time > 0:
                logger.info(f"â•‘  TTS è½¬æ¢:     {tts_time:>6.0f} ms                          â•‘")
            logger.info("â• " + "=" * 58 + "â•£")
            logger.info(f"â•‘  æ€»è€—æ—¶:       {total_time:>6.0f} ms                          â•‘")
            logger.info("â•š" + "=" * 58 + "â•")
                
        except Exception as e:
            logger.error(f"å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
            if channel == "voice":
                await self.tts_player.speak("æŠ±æ­‰ï¼Œå¤„ç†æ—¶å‡ºé”™äº†", interrupt=True)
            return ""

        return reply_text

    async def _handle_feishu_message(self, text: str, channel: str = "feishu") -> str:
        """å¤„ç†é£ä¹¦æ¶ˆæ¯"""
        return await self._process_user_message(text, channel="feishu")
    
    def _on_book_detected(self, vision_result: dict):
        """è§†è§‰åˆ†æå›è°ƒï¼šæ›´æ–°ä¹¦ç±ä¸Šä¸‹æ–‡"""
        book_title = vision_result.get("book_title", "")
        confidence = vision_result.get("confidence", 0)
        if book_title and confidence >= 0.7:
            self.memory.update_book_context(vision_result)
            logger.info(f"ğŸ“š ä¹¦åå·²è¯†åˆ«: ã€Š{book_title}ã€‹ï¼ˆç½®ä¿¡åº¦ {confidence:.2f}ï¼‰")

    # OCR è¿ç»­æ— å†…å®¹è¶…æ—¶ï¼šè¶…è¿‡æ­¤ç§’æ•°æ‰æ¸…ç©ºä¸Šä¸‹æ–‡
    _OCR_CLEAR_TIMEOUT_S = 60

    def _on_snapshot(self, ocr_text: str, image_path: str):
        """å¿«ç…§å›è°ƒï¼šå°† OCR æ–‡å­—å†™å…¥ AI ä¸Šä¸‹æ–‡"""
        MIN_OCR_LEN = 6  # å°‘äºæ­¤å­—æ•°è§†ä¸ºæ— æ•ˆå†…å®¹
        if not ocr_text or len(ocr_text.strip()) < MIN_OCR_LEN:
            # æ£€æŸ¥è·ä¸Šæ¬¡æœ‰æ•ˆ OCR æ˜¯å¦è¶…è¿‡è¶…æ—¶é˜ˆå€¼
            elapsed = time.time() - self._last_valid_ocr_ts
            if elapsed >= self._OCR_CLEAR_TIMEOUT_S:
                self.memory.set_page_context("")
                logger.info(f"ğŸ“– OCR æŒç»­ {elapsed:.0f}s æ— å†…å®¹ï¼Œå·²æ¸…ç©ºä¹¦é¡µä¸Šä¸‹æ–‡")
            else:
                logger.debug(f"ğŸ“– OCR æ— å†…å®¹ï¼ˆå·² {elapsed:.0f}sï¼‰ï¼Œä¿ç•™ä¸Šæ¬¡ä¸Šä¸‹æ–‡")
            return
        self._last_valid_ocr_ts = time.time()
        self.memory.set_page_context(ocr_text, image_path)
        preview = ocr_text[:80].replace('\n', ' ')
        logger.info(f"ğŸ“– ä¹¦é¡µä¸Šä¸‹æ–‡å·²æ³¨å…¥ ({len(ocr_text)}å­—) â†’ ä¸‹æ¬¡ AI å¯¹è¯ç”Ÿæ•ˆ")
        logger.info(f"   é¢„è§ˆ: {preview}â€¦")
    
    async def _check_and_push_feishu(self):
        """æ£€æŸ¥å¹¶æ¨é€é£ä¹¦æ€»ç»“"""
        if not self.feishu_bot or not self.summary_pusher:
            return


async def main():
    """å…¥å£å‡½æ•°"""
    app = ReadingCompanion()
    
    # ä¿¡å·å¤„ç†
    def signal_handler(sig, frame):
        logger.info("æ”¶åˆ°é€€å‡ºä¿¡å·...")
        if app.loop:
            asyncio.run_coroutine_threadsafe(app.shutdown(), app.loop)
    
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    try:
        await app.run()
    except Exception as e:
        logger.exception("ç¨‹åºå¼‚å¸¸é€€å‡º")
        raise


if __name__ == "__main__":
    asyncio.run(main())
