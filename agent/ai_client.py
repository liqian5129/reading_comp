"""
AI å®¢æˆ·ç«¯
æ”¯æŒ Kimi å’Œè±†åŒ…åŒæ¨¡å‹
"""
import base64
import json
import logging
import time
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from pathlib import Path

import openai
import httpx

logger = logging.getLogger(__name__)


@dataclass
class LLMResponse:
    """LLM å“åº”"""
    text: str
    tool_calls: List[Dict[str, Any]]
    stop_reason: str
    raw_assistant_message: Optional[Dict] = None  # å« tool_calls çš„åŸå§‹ assistant æ¶ˆæ¯


class AIClient:
    """
    AI å®¢æˆ·ç«¯
    æ”¯æŒ Kimi (Moonshot) å’Œè±†åŒ… (Volces/å­—èŠ‚)
    """
    
    def __init__(self, 
                 provider: str = "kimi",
                 api_key: str = "",
                 model: str = "",
                 base_url: str = "",
                 enable_thinking: bool = False):
        """
        Args:
            provider: æä¾›å•† - "kimi" æˆ– "doubao"
            api_key: API å¯†é’¥
            model: æ¨¡å‹åç§°
            base_url: API åŸºç¡€ URL
            enable_thinking: æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆä»… Kimi K2.5 æœ‰æ•ˆï¼‰
        """
        self.provider = provider.lower()
        self.api_key = api_key
        self.model = model
        self.base_url = base_url
        self.enable_thinking = enable_thinking
        
        # åˆ›å»º OpenAI å®¢æˆ·ç«¯ï¼Œæ·»åŠ è¯¦ç»†çš„ HTTP æ—¥å¿—
        self.client = openai.AsyncOpenAI(
            api_key=api_key,
            base_url=base_url,
            timeout=60.0,
        )
        
        logger.info(f"ğŸ¤– AI å®¢æˆ·ç«¯åˆå§‹åŒ–: {provider} / {model}")
        
        if self.provider == "kimi" and "k2" in model and not enable_thinking:
            logger.info("ğŸš€ Kimi K2.5 å·²å…³é—­ thinking æ¨¡å¼")
    
    def _get_temperature(self) -> float:
        """è·å–åˆé€‚çš„ temperature"""
        if self.provider == "kimi":
            # Kimi K2.5 å…³é—­ thinking æ—¶å¿…é¡»ç”¨ 0.6
            if "k2" in self.model and not self.enable_thinking:
                return 0.6
            return 1.0
        else:  # doubao
            return 0.7
    
    def _get_extra_body(self) -> Optional[Dict]:
        """è·å–é¢å¤–çš„è¯·æ±‚ä½“å‚æ•°"""
        # Kimi K2.5 å…³é—­ thinking
        if self.provider == "kimi" and "k2" in self.model and not self.enable_thinking:
            return {"thinking": {"type": "disabled"}}
        return None
    
    def _encode_image(self, image_path: str) -> Optional[str]:
        """å°†å›¾ç‰‡è½¬ä¸º base64"""
        try:
            path = Path(image_path)
            if not path.exists():
                return None
            
            with open(path, "rb") as f:
                image_data = f.read()
            
            ext = path.suffix.lower()
            media_type = {
                '.jpg': 'image/jpeg',
                '.jpeg': 'image/jpeg',
                '.png': 'image/png',
                '.gif': 'image/gif',
                '.webp': 'image/webp',
            }.get(ext, 'image/jpeg')
            
            return f"data:{media_type};base64,{base64.b64encode(image_data).decode()}"
        except Exception as e:
            logger.error(f"å›¾ç‰‡ç¼–ç å¤±è´¥: {e}")
            return None
    
    def _build_messages(self, 
                       system_prompt: str,
                       history: List[Dict[str, str]], 
                       user_message: str,
                       image_path: Optional[str] = None) -> List[Dict]:
        """æ„å»ºæ¶ˆæ¯åˆ—è¡¨"""
        messages = []
        
        if system_prompt:
            messages.append({
                "role": "system",
                "content": system_prompt
            })
        
        # æ·»åŠ å†å²æ¶ˆæ¯
        for msg in history[-20:]:
            messages.append(msg)
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        content = []
        
        if image_path:
            image_data = self._encode_image(image_path)
            if image_data:
                content.append({
                    "type": "image_url",
                    "image_url": {"url": image_data}
                })
        
        if isinstance(content, list):
            content.append({"type": "text", "text": user_message})
            messages.append({"role": "user", "content": content})
        else:
            messages.append({"role": "user", "content": user_message})
        
        return messages
    
    def _convert_tools(self, tools: List[Dict]) -> List[Dict]:
        """è½¬æ¢å·¥å…·æ ¼å¼ä¸º OpenAI æ ¼å¼"""
        converted = []
        for tool in tools:
            converted.append({
                "type": "function",
                "function": {
                    "name": tool["name"],
                    "description": tool["description"],
                    "parameters": tool.get("input_schema", {})
                }
            })
        return converted
    
    async def chat(self,
                   user_message: str,
                   system_prompt: str = "",
                   history: List[Dict[str, str]] = None,
                   image_path: Optional[str] = None,
                   tools: List[Dict] = None,
                   max_tokens: int = 4096) -> LLMResponse:
        """ä¸ AI å¯¹è¯ - å¸¦è¯¦ç»†è®¡æ—¶"""
        if history is None:
            history = []
        
        messages = self._build_messages(
            system_prompt, history, user_message, image_path
        )
        
        # è®¡ç®—è¯·æ±‚å¤§å°
        request_json = json.dumps({"messages": messages, "model": self.model})
        request_size_kb = len(request_json.encode('utf-8')) / 1024
        
        # å¼€å§‹è®¡æ—¶
        total_start = time.time()
        ttfb_start = None
        ttfb_end = None
        
        try:
            kwargs = {
                "model": self.model,
                "messages": messages,
                "max_tokens": max_tokens,
                "temperature": self._get_temperature(),
            }
            
            extra_body = self._get_extra_body()
            if extra_body:
                kwargs["extra_body"] = extra_body
            
            if tools:
                kwargs["tools"] = self._convert_tools(tools)
                kwargs["tool_choice"] = "auto"
            
            logger.info("=" * 60)
            logger.info(f"ğŸ“¤ AI è¯·æ±‚å¼€å§‹")
            logger.info(f"   æ¨¡å‹: {self.model}")
            logger.info(f"   æ¶ˆæ¯æ•°: {len(messages)}")
            logger.info(f"   è¯·æ±‚å¤§å°: {request_size_kb:.2f} KB")
            logger.info("-" * 60)
            
            # å‘é€è¯·æ±‚å¹¶è®¡æ—¶
            ttfb_start = time.time()
            
            response = await self.client.chat.completions.create(**kwargs)
            
            # é¦–å­—èŠ‚åˆ°è¾¾æ—¶é—´
            ttfb_end = time.time()
            ttfb_ms = (ttfb_end - ttfb_start) * 1000
            
            # å®Œæ•´å“åº”æ—¶é—´
            total_end = time.time()
            total_ms = (total_end - total_start) * 1000
            
            # è§£æå“åº”
            message = response.choices[0].message
            text = message.content or ""
            
            # å“åº”å¤§å°ä¼°ç®—
            response_json = json.dumps({"content": text}, ensure_ascii=False)
            response_size_kb = len(response_json.encode('utf-8')) / 1024
            
            # æå–å·¥å…·è°ƒç”¨
            tool_calls = []
            raw_assistant_message = None
            if message.tool_calls:
                for tc in message.tool_calls:
                    tool_calls.append({
                        "id": tc.id,
                        "name": tc.function.name,
                        "input": json.loads(tc.function.arguments)
                    })
                # ä¿å­˜åŸå§‹ assistant æ¶ˆæ¯ï¼ˆAPI è¦æ±‚ tool æ¶ˆæ¯å‰å¿…é¡»æœ‰æ­¤æ¶ˆæ¯ï¼‰
                raw_assistant_message = {
                    "role": "assistant",
                    "content": message.content,
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments,
                            },
                        }
                        for tc in message.tool_calls
                    ],
                }

            stop_reason = response.choices[0].finish_reason
            if tool_calls:
                stop_reason = "tool_use"
            
            # è®¡ç®—å„é˜¶æ®µæ—¶é—´
            server_process_ms = total_ms - ttfb_ms  # æœåŠ¡å™¨å¤„ç† + ç½‘ç»œä¼ è¾“
            
            logger.info(f"ğŸ“¥ AI å“åº”å®Œæˆ")
            logger.info(f"   TTFB (é¦–å­—èŠ‚æ—¶é—´): {ttfb_ms:.0f} ms")
            logger.info(f"   æ€»è€—æ—¶: {total_ms:.0f} ms")
            logger.info(f"   æœåŠ¡å™¨å¤„ç†+ä¼ è¾“: {server_process_ms:.0f} ms")
            logger.info(f"   å“åº”å¤§å°: {response_size_kb:.2f} KB")
            logger.info(f"   ç”Ÿæˆ tokens: ~{len(text)} å­—ç¬¦")
            logger.info(f"   åœæ­¢åŸå› : {stop_reason}")
            logger.info("=" * 60)
            
            return LLMResponse(
                text=text,
                tool_calls=tool_calls,
                stop_reason=stop_reason,
                raw_assistant_message=raw_assistant_message,
            )
            
        except Exception as e:
            total_end = time.time()
            total_ms = (total_end - total_start) * 1000
            
            if ttfb_start and not ttfb_end:
                # è¯·æ±‚å‘å‡ºä½†æ²¡æœ‰æ”¶åˆ°å“åº”
                logger.error(f"âŒ AI è¯·æ±‚è¶…æ—¶æˆ–å¤±è´¥ (å·²ç­‰å¾… {total_ms:.0f} ms)")
            else:
                logger.error(f"âŒ AI API è°ƒç”¨å¤±è´¥: {e}")
            
            return LLMResponse(
                text=f"æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜: {str(e)}",
                tool_calls=[],
                stop_reason="error"
            )
    
    async def chat_with_tool_result(self,
                                    user_message: str,
                                    tool_results: List[Dict],
                                    system_prompt: str = "",
                                    history: List[Dict[str, str]] = None,
                                    assistant_message: Optional[Dict] = None,
                                    max_tokens: int = 4096) -> LLMResponse:
        """å‘é€å·¥å…·æ‰§è¡Œç»“æœï¼Œç»§ç»­å¯¹è¯ - å¸¦è®¡æ—¶"""
        if history is None:
            history = []

        messages = []

        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})

        messages.extend(history[-20:])

        # å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_message})

        # assistant åŸå§‹æ¶ˆæ¯ï¼ˆå« tool_callsï¼‰ï¼ŒAPI å¼ºåˆ¶è¦æ±‚åœ¨ tool æ¶ˆæ¯ä¹‹å‰
        if assistant_message:
            messages.append(assistant_message)

        for result in tool_results:
            messages.append({
                "role": "tool",
                "tool_call_id": result["tool_use_id"],
                "content": result["content"]
            })
        
        total_start = time.time()
        
        try:
            kwargs = {
                "model": self.model,
                "messages": messages,
                "max_tokens": max_tokens,
                "temperature": self._get_temperature(),
            }
            
            extra_body = self._get_extra_body()
            if extra_body:
                kwargs["extra_body"] = extra_body
            
            response = await self.client.chat.completions.create(**kwargs)
            
            total_end = time.time()
            total_ms = (total_end - total_start) * 1000
            
            message = response.choices[0].message
            text = message.content or ""
            
            logger.info(f"ğŸ› ï¸ å·¥å…·ç»“æœå¤„ç†å®Œæˆ: {total_ms:.0f} ms")
            
            return LLMResponse(
                text=text,
                tool_calls=[],
                stop_reason=response.choices[0].finish_reason
            )
            
        except Exception as e:
            logger.error(f"AI API è°ƒç”¨å¤±è´¥: {e}")
            return LLMResponse(
                text=f"æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜: {str(e)}",
                tool_calls=[],
                stop_reason="error"
            )
